version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.2.2
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.2.2
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
    restart: unless-stopped

  kafka-connect:
    image: debezium/connect:1.9
    container_name: kafka-connect
    depends_on:
      - kafka
    ports:
      - "7083:8083"
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: connect_statuses
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
    restart: unless-stopped

  spark-master:
    image: apache/spark:3.5.0
    container_name: spark-master
    command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.master.Master","--host","spark-master"]
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./jars:/opt/spark-extra-jars
    restart: unless-stopped

  spark-worker:
    image: apache/spark:3.5.0
    container_name: spark-worker
    depends_on:
      - spark-master
    command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.worker.Worker","spark://spark-master:7077"]
    ports:
      - "8082:8081"
    volumes:
      - ./jars:/opt/spark-extra-jars
    restart: unless-stopped

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    depends_on:
      - kafka
      - kafka-connect
    ports:
      - "8081:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: FIRST
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect:8083
      DYNAMIC_CONFIG_ENABLED: "true"
    restart: unless-stopped

  jupyter:
    image: jupyter/pyspark-notebook:spark-3.5.0
    container_name: jupyter
    depends_on:
      - spark-master
    ports:
      - "8889:8888"
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./jars:/opt/spark-extra-jars
    command: >
      bash -lc "
        set -e;
        cp -f /opt/spark-extra-jars/spark-sql-kafka-0-10_2.12-3.5.0.jar /usr/local/spark/jars/ || true;
        cp -f /opt/spark-extra-jars/spark-token-provider-kafka-0-10_2.12-3.5.0.jar /usr/local/spark/jars/ || true;
        cp -f /opt/spark-extra-jars/kafka-clients-3.5.0.jar /usr/local/spark/jars/ || true;
        cp -f /opt/spark-extra-jars/hadoop-aws-3.3.4.jar /usr/local/spark/jars/ || true;
        cp -f /opt/spark-extra-jars/aws-java-sdk-bundle-1.12.262.jar /usr/local/spark/jars/ || true;
        cp -f /opt/spark-extra-jars/commons-pool2-2.11.1.jar /usr/local/spark/jars/ || true;
        exec start-notebook.sh
      "
    environment:
      - PYSPARK_SUBMIT_ARGS=--jars /opt/spark-extra-jars/spark-sql-kafka-0-10_2.12-3.5.0.jar,/opt/spark-extra-jars/spark-token-provider-kafka-0-10_2.12-3.5.0.jar,/opt/spark-extra-jars/kafka-clients-3.5.0.jar,/opt/spark-extra-jars/hadoop-aws-3.3.4.jar,/opt/spark-extra-jars/aws-java-sdk-bundle-1.12.262.jar,/opt/spark-extra-jars/commons-pool2-2.11.1.jar pyspark-shell
    restart: unless-stopped

  minio:
    image: minio/minio
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=changeme
      - MINIO_ROOT_PASSWORD=changeme
    command: server /data --console-address ":9001"
    volumes:
      - ./minio_data:/data
    restart: unless-stopped
